{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-6 sdxl1.0与应用\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 章节目标\n",
    "- sdxl的概念\n",
    "- sdxl与传统sd模型的区别\n",
    "- sdxl使用的几种方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 概念和应用场景\n",
    "sdxl是一种用于文本到图像合成的潜在扩散模型，包含2个模型(base和refiner)和2步过程(先使用基础模型base生成噪声潜在因素，再通过降噪细化模型refiner提升图片质量),其中基础模型base可以作为独立模块使用。同时可以使用两阶段通道(先用基础模型base生成所需输出大小的图像，再使用img2img得到高质量图像)，使用方式依赖于GPU显存。\n",
    "论文地址：https://arxiv.org/abs/2307.01952\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 sdxl与传统sd模型的区别\n",
    "sdxl1.0具有以下新特性：\n",
    "- 更好的成像质量，拥有更生动，准确的颜色，在对比度，光照和阴影等方面表现更好。\n",
    "- 更智能的语言提示，相对比以前的模型，sdxl能用更少的提示词获得复杂，详细，美观的图像，同时对概念差异的理解更深。比如某些提示词有多种概念，sdxl更能理解这种差异。\n",
    "- 更高的分辨率，sdxl基础分辨率为1024x1024，sd1.5为512x512，sd2为768x768。\n",
    "- 更高级的控制，sdxl的微调模型，微调模型适应自定义数据能力更高，即使用更少的数据整理来生成自定义LoRAs或检查点。\n",
    "技术上的更迭：\n",
    "- 相比于传统sd，sdxl拥有三倍大的UNet主干，主要改进为：\n",
    "1. UNet中transformer块放到较低层去计算。\n",
    "2. 文本编码器从单个CLIP换成了OpenClip ViT-bigG和Clip Vit-L两个合并。拥有更智能的语言提示，也使得sd1.5和sd2所训练的中文对齐模型失效。\n",
    "3. 用cross-attention做文本条件注入，同时增加了来自OpenClip池化了的文本嵌入。\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

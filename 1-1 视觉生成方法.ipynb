{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1-1 视觉生成方法\n",
    "\n",
    " (目录)\n",
    "\n",
    "## 0 章节目标\n",
    "- 了解视觉生成概念\n",
    "- 理解视觉生成的主要方法，并且能运用这些方法去解决问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1 概念\n",
    "在AIGC的时代，除了大家熟知的自然语言生成大模型非常重要以外，像DALL-E2、Stable-Diffusion、Midjourney等视觉生成大模型也同样重要，并且其视觉生成大模型在绘画、影视、自动驾驶、机器人、商业、游戏等诸多领域有着非常重要的应用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 什么是视觉生成大模型？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "视觉生成是计算机视觉领域的一个重要研究方向，指根据特定的输入（随机噪声、文本、图像和视频等）生成与目标分布相匹配的图像或视频，可以实现对图像和视频的生成、美化、渲染和重建等操作。  \n",
    "视觉生成技术在日常生活中有广泛的应用，比如视觉设计、图像/视频制作等。  \n",
    "视觉生成已经成为机器学习领域热门的方向之一。  \n",
    "视觉生成的目标是生成尽可能真实的数据，其关键在于构造生成模型。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[深度对抗视觉生成综述](http://www.cjig.cn/jig/ch/reader/create_pdf.aspx?file_no=20211201&flag=1&year_id=2021&quarter_id=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 视觉生成模型与自然语言生成模型的区别？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[自然语言生成综述](http://www.joca.cn/CN/10.11772/j.issn.1001-9081.2020071069)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自然语言最终要生成的是文本信息。  \n",
    "典型任务有：文本到文本生成、数据到文本生成和图像到文本生成。  \n",
    "应用场景  \n",
    "NLG 技术具有极为广泛的应用价值，应 用于智能问答对话系统和机器翻译系统时，可实现更为智能 便捷的人机交互；应用于机器新闻写作［2］ 、医学诊断报告生 成［3］ 和天气预报生成［4］ 等领域时，可实现文章报告自动撰写， 有效减轻人工工作；应用于文章摘要、文本复述领域时，可为 读者创造快速阅读条件等。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2 方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.1 生成对抗网络（GAN）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 是什么？\n",
    "- 原理（模型结构/算法原理+数学）\n",
    "- 应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 假如你是一名篮球运动员，你想在下次比赛中得到上场机会。\n",
    "于是在每一次训练赛之后你跟教练进行沟通：\n",
    "\n",
    "你：教练，我想打球\n",
    "教练：（评估你的训练赛表现之后）... 算了吧\n",
    "（你通过跟其他人比较，发现自己的运球很差，于是你苦练了一段时间）\n",
    "\n",
    "你：教练，我想打球\n",
    "教练：... 嗯 还不行\n",
    "（你发现大家投篮都很准，于是你苦练了一段时间的投篮）\n",
    "\n",
    "你：教练，我想打球\n",
    "教练： ... 嗯 还有所欠缺\n",
    "（你发现你的身体不够壮，被人一碰就倒，于是你去泡健身房）\n",
    "\n",
    "......\n",
    "\n",
    "通过这样不断的努力和被拒绝，你最终在某一次训练赛之后得到教练的赞赏，获得了上场的机会。\n",
    "值得一提的是在这个过程中，所有的候选球员都在不断地进步和提升。因而教练也要不断地通过对比场上球员和候补球员来学习分辨哪些球员是真正可以上场的，并且要“观察”得比球员更频繁。随着大家的成长教练也会会变得越来越严格。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![GAN](https://picx.zhimg.com/70/v2-5ca6a701d92341b8357830cc176fb8a3_1440w.avis?source=172ae18b&biz_tag=Post)\n",
    "<center>GAN网络的基本结构</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GAN的主要结构包括一个生成器G（Generator）和一个判别器D（Discriminator）。在上面的例子中的球员就相当于生成器，我们需要他在球场上能有好的表现。而球员一开始都是初学者，这个时候就需要一个教练员来指导他们训练，告诉他们训练得怎么样，直到真的能够达到上场的标准。而这个教练就相当于判别器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.2 变分自编码器（VAE）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先介绍AE(autoencoder)  \n",
    "算法原理、特点、局限性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 在介绍变分自编码器之前，先来了解下自编码器。\n",
    "- 自编码器主要由编码器和解码器组成。\n",
    "- 自编码器可以通过编码(coding)学习输入数据的隐含特征，之后用学到的新特征重构出原始的输入数据，称之为解码(decoding)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[An Introduction to Autoencoders](https://arxiv.org/pdf/2201.03898.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![autoencoder arch](images/插图002.jpg)\n",
    "<center>自编码器的一般结构</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 考虑内容生成问题\n",
    "- autoencoder在内容生成上的局限性\n",
    "- 自编码器用于内容生成的局限性\n",
    "- 变分自编码器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Understanding Variational Autoencoders (VAEs)](https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-09T20:03:48.895323Z",
     "start_time": "2023-09-09T20:03:48.895067Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.3 流模型（flow-based model）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 是什么，如何认识“流”\n",
    "- 算法原理，如何生成\n",
    "- 实现代码\n",
    "- 应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Flow-based Generative Model](http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2019/Lecture/FLOW%20(v7).pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 是什么：\n",
    "- 流(Flow-based)模型旨在通过一系列可逆变换(双射函数)建立较为简单的先验分布与较为复杂的实际数据分布之间的映射关系。根据概率密度的变量替换公式，不需要显式地计算实际数据分布的概率密度函数，而是通过先验分布的概率密度以及映射过程产生的Jacobian行列式计算即可。\n",
    "- 在实现时通过复合多个双射函数以增强非线性拟合能力。模型整体像水管中的流水一样汇聚，因此称为流模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 实现代码：\n",
    "- 使用nflows构造流模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pip install nflows\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 构造流模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "from nflows import transforms, distributions, flows\n",
    "\n",
    "# Define an invertible transformation.\n",
    "transforms = []\n",
    "for _ in range(num_layers):\n",
    "    transforms.append(transforms.ReversePermutation(features=2))\n",
    "    transforms.append(transforms.MaskedAffineAutoregressiveTransform(features=2, \n",
    "                                                                     hidden_features=4))\n",
    "transform = CompositeTransform(transforms)\n",
    "\n",
    "# Define a base distribution.\n",
    "base_distribution = distributions.StandardNormal(shape=[2])\n",
    "\n",
    "# Combine into a flow.\n",
    "flow = flows.Flow(transform=transform, distribution=base_distribution)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 目标函数为负对数似然："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "optimizer = optim.Adam(flow.parameters())\n",
    "\n",
    "for i in range(num_iter):\n",
    "    # Calculate loss and update gradient.\n",
    "    optimizer.zero_grad()\n",
    "    loss = -flow.log_prob(inputs).mean()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 从流模型中采样："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "samples = flow.sample(num_samples)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.4 扩散模型（Diffusion model）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 梳理结构，填充内容\n",
    "- 是什么？\n",
    "- 原理（算法原理）\n",
    "- 少量数学原理\n",
    "- 应用，落地"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[扩散模型(Diffusion Model)首篇综述-Diffusion Models: A Comprehensive Survey of Methods and Applications](https://arxiv.org/pdf/2209.00796.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 扩散模型（diffusion models）是深度生成模型中新的SOTA\n",
    "- 其中一种方法是“扩散模型”——一种从气体扩散的物理过程中获得灵感的方法，并试图在多个科学领域对同一现象进行建模。\n",
    "- 它运用了物理热力学中的扩散思想，主要包括前向扩散和反向扩散两个过程\n",
    "- 扩散的思想来自物理学中的非平衡热力学分支。非平衡热力学专门研究某些不处于热力学平衡中的物理系统，其中最为典型的研究案例是一滴墨水在水中扩散的过程。在扩散开始之前，这滴墨水会在水中的某个地方形成一个大的斑点，我们可以认为这是这滴墨水的初始状态，但要描述该初始状态的概率分布则很困难，因为这个概率分布非常复杂。随着扩散过程的进行，这滴墨水随着时间的推移逐步扩散到水中，水的颜色也逐渐变成这滴墨水的颜色，如图1-1所示。此时，墨水分子的概率分布将变得更加简单和均匀，这样我们就可以很轻松地用数学公式来描述其中的概率分布了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![插图001](images/插图001.jpg)\n",
    "<center>一滴墨水在水中扩散分布的示意图</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 原理（算法原理）\n",
    "- 扩散过程分为前向扩散过程和反向过程。\n",
    "- 前向扩散过程\n",
    "- 反向扩散过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 应用？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 扩散模型在图片生成任务中超越了原SOTA：GAN，并且在诸多应用领域都有出色的表现，如计算机视觉，NLP、波形信号处理、多模态建模、分子图建模、时间序列建模、对抗性净化等。\n",
    "- 此外，扩散模型与其他研究领域有着密切的联系，如稳健学习、表示学习、强化学习。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dyh",
   "language": "python",
   "name": "dyh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
